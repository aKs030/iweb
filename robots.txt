# robots.txt - AI & Search Engine Directives

# Default: Allow all bots
User-agent: *
Allow: /
Crawl-delay: 1

# Sitemaps
Sitemap: https://www.abdulkerimsesli.de/sitemap.xml
Sitemap: https://www.abdulkerimsesli.de/sitemap-images.xml
Sitemap: https://www.abdulkerimsesli.de/sitemap-videos.xml

# AI-specific directives
# OpenAI GPT
User-agent: GPTBot
Allow: /
Crawl-delay: 1

# Anthropic Claude
User-agent: Claude-Web
Allow: /
Crawl-delay: 1

# Google Bard/Gemini
User-agent: Google-Extended
Allow: /
Crawl-delay: 1

# Perplexity AI
User-agent: PerplexityBot
Allow: /
Crawl-delay: 1

# Common Crawl (used by many AI systems)
User-agent: CCBot
Allow: /
Crawl-delay: 2

# Cohere AI
User-agent: cohere-ai
Allow: /
Crawl-delay: 1

# AI2 Bot (Allen Institute)
User-agent: AI2Bot
Allow: /
Crawl-delay: 1

# Applebot (used for Siri, Spotlight)
User-agent: Applebot
Allow: /
Crawl-delay: 1

# Disallow sensitive areas
User-agent: *
Disallow: /api/
Disallow: /.wrangler/
Disallow: /node_modules/
Disallow: /*.log$

# LLM-specific files
Allow: /llms.txt
Allow: /llms-full.txt
Allow: /ai-index.json
