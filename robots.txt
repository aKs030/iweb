# robots.txt for abdulkerimsesli.de
# Minimal, Google-friendly configuration

# Sitemap locations
Sitemap: https://abdulkerimsesli.de/sitemap.xml
Sitemap: https://abdulkerimsesli.de/sitemap-images.xml
Sitemap: https://abdulkerimsesli.de/sitemap-videos.xml
Sitemap: https://abdulkerimsesli.de/ai-sitemap.xml

# Default rules for all crawlers
User-agent: *
Allow: /

# Block veraltete URL-Pfade (Legacy nach Refactoring)
# Diese Pfade existieren nicht mehr und werden per 301 umgeleitet
# Blockierung beschleunigt De-Indexierung in Google
Disallow: /pages/album.html
Disallow: /pages/ubermich.html
Disallow: /pages/index-game.html
Disallow: /pages/features/
Disallow: /pages/komponente/
Disallow: /content/footer/

# Note: Wildcards und regex (*.html$, *.js$) werden von Googlebot NICHT unterstützt
# Nur explizite Pfade oder Ordner mit / am Ende verwenden

# Allow wichtige Footer-Seiten (werden über clean URLs zugänglich gemacht)
Allow: /impressum/
Allow: /datenschutz/

# Allow crawling of the component redirects so Google sees the 301
Allow: /content/components/footer/datenschutz.html
Allow: /content/components/footer/impressum.html

# Note: video sitemap above added to improve video indexing
# If you add more video content, run: YT_API_KEY=<key> python3 scripts/update_video_sitemap.py
# Relaxed rules to improve rendering: allow JS/CSS/JSON where needed while keeping dev files blocked
# Keep broad disallows but explicitly allow static asset types (Google honors most-specific rule)
Disallow: /content/config/
Disallow: /content/utils/

# Allow JSON manifest and other JSON structured data
Allow: /manifest.json

# Allow rendering-critical component and style assets (JS/CSS)
Allow: /content/components/
Allow: /content/styles/
Allow: /content/main.js

# Local/dev files and folders (should never be crawled)
Disallow: /node_modules/
Disallow: /tmp/
Disallow: /dev/
Disallow: /README.DEV.md
Disallow: /dev-server.log
Disallow: /.live-server.json

# Google-specific rules
User-agent: Googlebot
Allow: /

# Google Image Bot
User-agent: Googlebot-Image
Allow: /

# Google Video Bot
User-agent: Googlebot-Video
Allow: /

# Bing Bot
User-agent: Bingbot
Allow: /
Crawl-delay: 5

# Other useful bots
User-agent: Slurp
Allow: /

# Reduce crawl rate for less-friendly crawlers
User-agent: *
# Note: Crawl-delay supported by some crawlers; Google ignores it
Crawl-delay: 1

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

# Social Media Bots (for previews)
User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: Pinterestbot
Allow: /

# Explicitly allow known AI/LLM crawlers so they can access sitemaps and structured data
User-agent: gptbot
Allow: /

User-agent: OpenAI
Allow: /

User-agent: openai
Allow: /

User-agent: Anthropic
Allow: /

User-agent: Perplexity
Allow: /

User-agent: PerplexityBot
Allow: /

# Block aggressive or unwanted bots
User-agent: MJ12bot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: dotbot
Disallow: /

User-agent: rogerbot
Disallow: /

# Archive.org allowed
User-agent: ia_archiver
Allow: /

# Contact / last updated
# Contact: https://abdulkerimsesli.de/about/
# Last updated: 2025-12-22
